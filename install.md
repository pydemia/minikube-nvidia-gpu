# Minikube

## none, nvidia-docker

* https://minikube.sigs.k8s.io/docs/tutorials/nvidia_gpu/#using-the-none-driver
* https://docs.nvidia.com/datacenter/cloud-native/container-toolkit/install-guide.html#setting-up-nvidia-container-toolkit

### Setting up NVIDIA Container Toolkit

```bash
distribution=$(. /etc/os-release;echo $ID$VERSION_ID) \
   && curl -s -L https://nvidia.github.io/nvidia-docker/gpgkey | sudo apt-key add - \
   && curl -s -L https://nvidia.github.io/nvidia-docker/$distribution/nvidia-docker.list | sudo tee /etc/apt/sources.list.d/nvidia-docker.list

sudo apt-get update
sudo apt-get install -y nvidia-docker2
```

Change default runtime to `nvidia`:
`/etc/docker/daemon.json`
```diff
{
++  "default-runtime": "nvidia",
    "runtimes": {
        "nvidia": {
            "path": "nvidia-container-runtime",
            "runtimeArgs": []
        }
    }
}
```

```bash
sudo systemctl restart docker
```

Test:

```bash
sudo docker run --rm --gpus all nvidia/cuda:11.0-base nvidia-smi
```

## Run minikube

```bash
$ minikube start --kubernetes-version=v1.18.17 --driver=none --apiserver-ips 127.0.0.1 --apiserver-name localhost

ğŸ˜„  minikube v1.22.0 on Ubuntu 20.04
â—  Kubernetes 1.18.17 has a known performance issue on cluster startup. It might take 2 to 3 minutes for a cluster to start.
â—  For more information, see: https://github.com/kubernetes/kubeadm/issues/2395
âœ¨  Using the none driver based on user configuration
ğŸ‘  Starting control plane node minikube in cluster minikube
ğŸ¤¹  Running on localhost (CPUs=20, Memory=64324MB, Disk=937366MB) ...
â„¹ï¸  OS release is Ubuntu 20.04.2 LTS
ğŸ³  Preparing Kubernetes v1.18.17 on Docker 20.10.2 ...
    â–ª kubelet.resolv-conf=/run/systemd/resolve/resolv.conf
    > kubectl.sha256: 64 B / 64 B [--------------------------] 100.00% ? p/s 0s
    > kubeadm.sha256: 64 B / 64 B [--------------------------] 100.00% ? p/s 0s
    > kubelet.sha256: 64 B / 64 B [--------------------------] 100.00% ? p/s 0s
    > kubeadm: 37.93 MiB / 37.93 MiB [---------------] 100.00% 1.84 MiB p/s 21s
    > kubectl: 41.95 MiB / 41.95 MiB [---------------] 100.00% 1.96 MiB p/s 22s
    > kubelet: 108.04 MiB / 108.04 MiB [------------] 100.00% 1.57 MiB p/s 1m9s
    â–ª Generating certificates and keys ...
    â–ª Booting up control plane ...
    â–ª Configuring RBAC rules ...
ğŸ¤¹  Configuring local host environment ...

â—  The 'none' driver is designed for experts who need to integrate with an existing VM
ğŸ’¡  Most users should use the newer 'docker' driver instead, which does not require root!
ğŸ“˜  For more information, see: https://minikube.sigs.k8s.io/docs/reference/drivers/none/

â—  kubectl and minikube configuration will be stored in /home/airuntime
â—  To use kubectl or minikube commands as your own user, you may need to relocate them. For example, to overwrite your own settings, run:

    â–ª sudo mv /home/airuntime/.kube /home/airuntime/.minikube $HOME
    â–ª sudo chown -R $USER $HOME/.kube $HOME/.minikube

ğŸ’¡  This can also be done automatically by setting the env var CHANGE_MINIKUBE_NONE_USER=true
ğŸ”  Verifying Kubernetes components...
    â–ª Using image gcr.io/k8s-minikube/storage-provisioner:v5
ğŸŒŸ  Enabled addons: default-storageclass, storage-provisioner

â—  /usr/bin/kubectl is version 1.21.3, which may have incompatibilites with Kubernetes 1.18.17.
    â–ª Want kubectl v1.18.17? Try 'minikube kubectl -- get pods -A'
ğŸ„  Done! kubectl is now configured to use "minikube" cluster and "default" namespace by default
```

```bash
$ kubectl create -f https://raw.githubusercontent.com/NVIDIA/k8s-device-plugin/master/nvidia-device-plugin.yml
daemonset.apps/nvidia-device-plugin-daemonset created
```

```bash
apiVersion: v1
kind: Pod
metadata:
  name: cuda-vector-add
spec:
  restartPolicy: OnFailure
  containers:
    - name: cuda-vector-add
      # https://github.com/kubernetes/kubernetes/blob/v1.7.11/test/images/nvidia-cuda/Dockerfile
      image: "k8s.gcr.io/cuda-vector-add:v0.1"
      resources:
        limits:
          nvidia.com/gpu: 1 # requesting 1 GPU
```
